% !TeX root=main.tex
\chapter{نتیجه‌گیری و پیشنهادات}
\thispagestyle{empty}

\section{نتیجه‌گیری}
در این پروژه روش 
\lr{Adv-GAN}
به عنوان یک روش حمله نوین و قدرتمند به شبکه‌های عصبی عمیق بررسی شد. ایده‌ی اصلی این شبکه برگرفته از شبکه‌های مولد تقابلی است. از این روش می‌توان در حمله‌های جعبه نیمه‌سفید و جعبه سیاه با درصد موفقیت حمله‌ی بالا استفاده کرد زیرا هنگامی که بخش مولد شبکه 
\lr{Adv-GAN}
آموزش دیده است، می‌تواند به صورت مستقل، دستکاری‌های تقابلی‌ای را به صورت بهینه تولید کند.
\\
نمونه‌های تقابلی تولید شده توسط این روش دارای کیفیت واقعی بسیار بالایی هستند و بنابراین این روش یک کاندید بسیار قوی در هنگام بررسی و ارزیابی شبکه‌های عصبی عمیق در برابر نمونه‌های تقابلی است. 
\\
شبکه آموزش داده شده توانست عملکرد بسیار عالی شبکه هدف را از 
\lr{۹۹/۳\%}
به عملکرد کاملا اشتباه
\lr{۰/۴۳\%}
تنزل بدهد.
\\
شایان توجه است که وجود این نمونه‌های تقابلی نشان می‌دهد، توانایی خوب در توضیح مجموعه داده یا حتی برچسب‌زنی دقت بالا این داده‌ها، لزوما به این معنی نیست که مدل به درستی متوجه وظیفه‌ای که بر عهده‌اش است، شده است و در مقابل نمونه‌هایی که عمدا دستکاری شده‌اند مقاوم است.


\section{پیشنهادات و کار‌های آینده}
آسیب‌پذیری شبکه‌های عصبی به ‌نمونه‌‌های تقابلی باعث شده است که پژوهش‌ها در زمینه حمله‌های تقابلی و راه‌های دقاع آن در حال حاضر بسیار فعال شود. در برخی از پژوهش‌ها تکنیک‌هایی برای دفاع از شبکه‌های عصبی در مقابل روش‌های حمله شناخته شده، ارائه می‌شود و در سمتی دیگر روش‌هایی برای حمله‌های قدرتمند‌تر در حال طراحی و ارائه است. در برخی از پژوهش‌ها از شبکه‌های مولد تقابلی برای هر دو منظور استفاده شده است. امید است که این فعالیت و کوشش فراوان باعث شود تا روش‌های یادگیری عمیق بسیار مقاوم‌تر در حوزه کابردهای حساس امنیتی و ایمنی در جهان واقعی شود و حمله‌کننده‌ها توانایی اعمال دخالت و خراب‌کاری در شبکه را نداشته باشند.
\\ 
از این رو، بررسی کردن عملکرد این روش‌های حمله بر روی مجموعه‌داده‌های پیچیده و پردسته‌تر مانند 
\lr{CIFAR-100}
و
\lr{ImageNet}
و همچنین اعمال این روش‌های حمله بر روی شبکه‌های 
\lr{Recurrent}
و مجموعه‌داده‌های متنی و غیر تصویری قدمی دیگر به سوی شبکه‌های قابل اطمینان تر است.


